"""Use contest ID to update Google Sheet with DFS results."""
import argparse
import csv
import datetime
import io
import json
import logging
import pickle
import requests

# from unidecode import unidecode
import time
import unicodedata
import zipfile

from os import path

# from http.cookiejar import CookieJar
# from pprint import pprint
# from bs4 import BeautifulSoup
import browsercookie

from selenium import webdriver

from googleapiclient.discovery import build
from httplib2 import Http
from oauth2client import file, client, tools


logger = logging.getLogger(__name__)


class EST5EDT(datetime.tzinfo):
    """Create pz timezone for EST/EDT."""

    def utcoffset(self, dt):
        """Set UTC offset."""
        return datetime.timedelta(hours=-5) + self.dst(dt)

    def dst(self, dt):
        """Determine if DST is necessary depending on dates."""
        d = datetime.datetime(dt.year, 3, 8)  # 2nd Sunday in March
        self.dston = d + datetime.timedelta(days=6 - d.weekday())
        d = datetime.datetime(dt.year, 11, 1)  # 1st Sunday in Nov
        self.dstoff = d + datetime.timedelta(days=6 - d.weekday())
        if self.dston <= dt.replace(tzinfo=None) < self.dstoff:
            return datetime.timedelta(hours=1)
        else:
            return datetime.timedelta(0)

    def tzname(self, dt):
        """Return name of timezone."""
        return "EST5EDT"


def strip_accents(s):
    """Strip accents from a given string and replace with letters without accents."""
    return "".join(
        c for c in unicodedata.normalize("NFD", s) if unicodedata.category(c) != "Mn"
    )


# def pull_soup_data(filename, ENDPOINT):
#     """Either pull file from html or from file."""
#     soup = None
#     if not path.isfile(filename):
#         print("{} does not exist. Pulling from endpoint [{}]".format(filename, ENDPOINT))
#
#         # set cookies based on Chrome session
#         # cookies = browsercookie.chrome()
#         with open('cookies.json') as f:
#             cookies = json.loads(f)
#
#         pprint(cookies)
#
#         # send GET request
#         r = requests.get(ENDPOINT, cookies=cookies)
#         status = r.status_code
#
#         # if not successful, raise an exception
#         if status != 200:
#             raise Exception('Requests status != 200. It is: {0}'.format(status))
#
#         # dump html to file to avoid multiple requests
#         with open(filename, 'w') as outfile:
#             print(r.text, file=outfile)
#
#         soup = BeautifulSoup(r.text, 'html5lib')
#     else:
#         print("File exists [{}]. Nice!".format(filename))
#         # load html from file
#         with open(filename, 'r') as html_file:
#             soup = BeautifulSoup(html_file, 'html5lib')
#
#     return soup


def pull_salary_csv(filename, csv_url):
    """Pull CSV for salary information."""
    with requests.Session() as s:
        download = s.get(csv_url)

        decoded_content = download.content.decode("utf-8")

        cr = csv.reader(decoded_content.splitlines(), delimiter=",")
        my_list = list(cr)

        return my_list


def cj_from_cookies_json(working_cookies):
    filename = "cookies.json"

    # create empty cookie jar
    cj = requests.cookies.RequestsCookieJar()

    now = datetime.datetime.now()
    with open(filename) as f:
        cookies = json.load(f)
        for c in cookies:
            if c["name"] in working_cookies:
                # logger.info("found {} in working_cookies".format(c['name']))

                # some (one?) cookies do not have an expirationDate
                if "expirationDate" not in c:
                    logger.debug("{} has no expirationDate".format(c["name"]))
                    c["expirationDate"] = None

                # create cookie object
                r_cookie = requests.cookies.create_cookie(
                    name=c["name"],
                    value=c["value"],
                    domain=c["domain"],
                    path=c["path"],
                    expires=c["expirationDate"],
                )

                # logger.debug("name: {} expires: {}".format(
                #     r_cookie.name, r_cookie.expires))

                try:
                    if r_cookie.expires:
                        cookie_expiration = datetime.datetime.fromtimestamp(
                            r_cookie.expires
                        )
                        diff = cookie_expiration - now
                        if diff.total_seconds() >= 0:
                            logger.info(
                                "c.name {} expires soon. difference: {} (c.expires: {} now: {})".format(
                                    r_cookie.name, diff, cookie_expiration, now
                                )
                            )
                        else:
                            logger.info(
                                "c.name {} EXPIRED {} ago (c.expires: {} now: {})".format(
                                    r_cookie.name,
                                    now - cookie_expiration,
                                    cookie_expiration,
                                    now,
                                )
                            )
                # some cookies have unnecessarily long expiration times which produce overflow errors
                except OverflowError as e:
                    logger.debug("Overflow on {} [{}]".format(r_cookie.name, e))

                # add cookie to cookiejar
                cj.set_cookie(r_cookie)

    return cj


def cj_from_pickle(filename):
    try:
        with open(filename, "rb") as f:
            return pickle.load(f)
    except FileNotFoundError as e:
        logger.error("File {} not found [{}]".format(filename, e))
        return False


def setup_session(contest_csv_url, cookies):
    s = requests.Session()
    now = datetime.datetime.now()

    for c in cookies:
        # if the cookies already exists from a legitimate fresh session, clear them out
        if c.name in s.cookies:
            logger.debug("removing {} from 'cookies' -- ".format(c.name), end="")
            cookies.clear(c.domain, c.path, c.name)
        else:
            if not c.expires:
                continue

            try:
                if c.expires <= now.timestamp():
                    logger.debug(
                        "c.name {} has EXPIRED!!! (c.expires: {} now: {})".format(
                            c.name, datetime.datetime.fromtimestamp(c.expires), now
                        )
                    )
                else:  # check if
                    delta_hours = 5
                    d = datetime.datetime.fromtimestamp(c.expires) - datetime.timedelta(
                        hours=delta_hours
                    )
                    # within 5 hours
                    if d <= now:
                        logger.debug(
                            "c.name {} expires within {} hours!! difference: {} (c.expires: {} now: {})".format(
                                c.name,
                                delta_hours,
                                datetime.datetime.fromtimestamp(c.expires) - now,
                                datetime.datetime.fromtimestamp(c.expires),
                                now,
                            )
                        )
            # some cookies have unnecessarily long expiration times which produce overflow errors
            except OverflowError as e:
                logger.debug(
                    "Overflow on {} {} [error: {}]".format(c.name, c.expires, e)
                )

    # exit()
    logger.debug("adding all missing cookies to session.cookies")
    # print(cookies)
    s.cookies.update(cookies)

    return request_contest_url(s, contest_csv_url)


def request_contest_url(s, contest_csv_url):
    # attempt to GET contest_csv_url
    r = s.get(contest_csv_url)
    logger.debug(r.status_code)
    logger.debug(r.url)
    logger.debug(r.headers["Content-Type"])
    # print(r.headers)
    if "text/html" in r.headers["Content-Type"]:
        # write broken cookies
        with open("pickled_cookies_broken.txt", "wb") as f:
            pickle.dump(s.cookies, f)

        logger.info("We cannot do anything with html!")
        return False
    # if headers say file is a CSV file
    elif r.headers["Content-Type"] == "text/csv":

        # write working cookies
        with open("pickled_cookies_works.txt", "wb") as f:
            pickle.dump(s.cookies, f)
        # decode bytes into string
        csvfile = r.content.decode("utf-8")
        # open reader object on csvfile
        rdr = csv.reader(csvfile.splitlines(), delimiter=",")
        # return list
        return list(rdr)
    else:
        # write working cookies
        with open("pickled_cookies_works.txt", "wb") as f:
            pickle.dump(s.cookies, f)

        # request will be a zip file
        z = zipfile.ZipFile(io.BytesIO(r.content))
        for name in z.namelist():
            # extract file - it seems easier this way
            z.extract(name)
            with z.open(name) as csvfile:
                logger.debug("name within zipfile: {}".format(name))
                # convert to TextIOWrapper object
                lines = io.TextIOWrapper(csvfile, encoding="utf-8", newline="\r\n")
                # open reader object on csvfile within zip file
                rdr = csv.reader(lines, delimiter=",")
                return list(rdr)


def text_cookie_issue():
    # create/check file for date
    filename = "last_text_time.txt"
    now = datetime.datetime.now()

    if path.isfile(filename):
        with open(filename, "r+") as f:
            last_time = f.read()
            last_time_dt = datetime.datetime.strptime(last_time, "%Y-%m-%d %H:%M:%S.%f")
            logger.debug("Last text time: {}".format(last_time_dt))

            # if it has been less than an hour, don't text
            if now - last_time_dt < datetime.timedelta(minutes=30):
                logger.debug("It has only been: {} ".format(now - last_time_dt))
            else:
                logger.debug(
                    "it has been more than the cutoff! {} ".format(now - last_time_dt)
                )
                logger.debug("texting adam!")
    else:
        with open(filename, "w+") as f:
            logger.debug("Writing now(): {}".format(now))
            f.write("{}".format(now))


def pull_contest_zip(filename, contest_id):
    """Pull contest file (so far can be .zip or .csv file)."""
    contest_csv_url = "https://www.draftkings.com/contest/exportfullstandingscsv/{0}".format(
        contest_id
    )

    # cookies = browsercookie.chrome()
    # for c in cookies:
    #     if 'draft' not in c.domain:
    #         print("Clearing {} {} {} ".format(c.domain, c.path, c.name))
    #         cookies.clear(c.domain, c.path, c.name)
    #
    # # retrieve exported contest csv
    # s = requests.Session()
    # r = s.get(contest_csv_url, cookies=cookies)

    # try pickle cookies method
    cookies = cj_from_pickle("pickled_cookies_works.txt")
    if cookies:
        result = setup_session(contest_csv_url, cookies)

        logger.debug("type(result): {}".format(type(result)))
        if result is False:
            logger.debug("Broken from pickle method")
        else:
            logger.debug("pickle method worked!!")
            return result

    # try browsercookie method
    cookies = browsercookie.chrome()

    for c in cookies:
        if "draft" not in c.domain:
            logger.debug("Clearing {} {} {} ".format(c.domain, c.path, c.name))
            cookies.clear(c.domain, c.path, c.name)
        else:
            if c.expires:
                # chrome is ridiculous - this math is required
                # Devide the actual timestamp (in my case it's expires_utc column in cookies table) by 1000000 // And someone should explain my why.
                # Subtract 11644473600
                # DONE! Now you got UNIX timestamp
                new_expiry = c.expires / 1000000
                new_expiry -= 11644473600
                c.expires = new_expiry

    result = setup_session(contest_csv_url, cookies)
    logger.debug("type(result): {}".format(type(result)))

    if result is False:
        logger.debug("Broken from browsercookie method")
    else:
        logger.debug("browsercookie method worked!!")
        return result

    # use selenium to refresh cookies
    use_selenium(contest_csv_url)

    # try browsercookie method again
    cookies = browsercookie.chrome()

    for c in cookies:
        if "draft" not in c.domain:
            logger.debug("Clearing {} {} {} ".format(c.domain, c.path, c.name))
            cookies.clear(c.domain, c.path, c.name)
        else:
            if c.expires:
                # chrome is ridiculous - this math is required
                # Devide the actual timestamp (in my case it's expires_utc column in cookies table) by 1000000 // And someone should explain my why.
                # Subtract 11644473600
                # DONE! Now you got UNIX timestamp
                new_expiry = c.expires / 1000000
                new_expiry -= 11644473600
                c.expires = new_expiry

    result = setup_session(contest_csv_url, cookies)
    logger.debug("type(result): {}".format(type(result)))

    if result is False:
        logger.debug("Broken from SECOND browsercookie method")
    else:
        logger.debug("SECOND browsercookie method worked!!")
        return result
    #

    # trying load pickle cookie method
    # s.get('https://www.draftkings.com/')

    # with open('cookies.json') as f:
    #     cookies = json.load(f)
    #     for c in cookies:
    #         if c['name'] in s.cookies:
    #             print("removing {} from 'cookies' -- ".format(c.name), end='')
    #             cookies.clear(c.domain, c.path, c.name)

    #         else:
    #             print("did not find {} in s.cookies".format(c['name']))
    #             cookie = requests.cookies.create_cookie(
    #                 name=c['name'], value=c['value'], domain=c['domain'], path=c['path'], secure=c['secure'])
    #             s.cookies.set_cookie(cookie)


def use_selenium(contest_csv_url):
    logger.debug("Creating and adding options")
    options = webdriver.ChromeOptions()
    options.add_argument("--no-sandbox")
    options.add_argument("--user-data-dir=/home/pi/.config/chromium")
    options.add_argument("--profile-directory=Profile 1")
    # options.headless = True
    # print("Converting options to capabilities")
    # options = options.to_capabilities()
    logger.debug("Starting driver with options")
    driver = webdriver.Chrome(
        executable_path="/usr/bin/chromedriver",
        desired_capabilities=options.to_capabilities(),
    )
    # driver = webdriver.Remote(service.service_url, options)

    logger.debug("Performing get on {}".format(contest_csv_url))
    driver.get(contest_csv_url)
    logger.debug(driver.current_url)
    logger.debug("Letting DK load ...")
    time.sleep(5)  # Let DK Load!
    logger.debug(driver.current_url)
    logger.debug("Letting DK load ...")
    time.sleep(5)  # Let DK Load!
    logger.debug(driver.current_url)
    logger.debug("Quitting driver")
    driver.quit()


def add_header_format(service, spreadsheet_id, sheet_id):
    """Format header (row 0) with white text on black blackground."""
    header_range = {
        "sheetId": sheet_id,
        "startRowIndex": 0,
        "endRowIndex": 1,
        "startColumnIndex": 0,  # A
        "endColumnIndex": 7,  # F
    }
    color_black = {"red": 0.0, "green": 0.0, "blue": 0.0}
    color_white = {"red": 1.0, "green": 1.0, "blue": 1.0}
    requests = [
        {
            "repeatCell": {
                "range": header_range,
                "cell": {
                    "userEnteredFormat": {
                        "backgroundColor": color_black,
                        "horizontalAlignment": "CENTER",
                        "textFormat": {
                            "foregroundColor": color_white,
                            "fontFamily": "Trebuchet MS",
                            "fontSize": 10,
                            "bold": True,
                        },
                    }
                },
                "fields": "userEnteredFormat(backgroundColor, textFormat, horizontalAlignment)",
            }
        },
        {
            "updateSheetProperties": {
                "properties": {
                    "sheetId": sheet_id,
                    "gridProperties": {"frozenRowCount": 1},
                },
                "fields": "gridProperties.frozenRowCount",
            }
        },
    ]
    logger.info("Applying header to sheet")
    batch_update_sheet(service, spreadsheet_id, requests)


def add_col_num_fmt(service, spreadsheet_id, sheet_id):
    """Format each specified column with explicit number format."""
    range_ownership = {
        "sheetId": sheet_id,
        "startRowIndex": 1,
        "endRowIndex": 1000,
        "startColumnIndex": 5,  # F
        "endColumnIndex": 6,
    }
    range_points = {
        "sheetId": sheet_id,
        "startRowIndex": 1,
        "endRowIndex": 1000,
        "startColumnIndex": 6,  # G
        "endColumnIndex": 7,
    }
    range_value = {
        "sheetId": sheet_id,
        "startRowIndex": 1,
        "endRowIndex": 1000,
        "startColumnIndex": 7,  # H
        "endColumnIndex": 8,
    }
    requests = [
        {
            "repeatCell": {
                "range": range_ownership,
                "cell": {
                    "userEnteredFormat": {
                        "numberFormat": {"type": "NUMBER", "pattern": "#0.00%"}
                    }
                },
                "fields": "userEnteredFormat.numberFormat",
            }
        },
        {
            "repeatCell": {
                "range": range_points,
                "cell": {
                    "userEnteredFormat": {
                        "numberFormat": {"type": "NUMBER", "pattern": "##0.00"}
                    }
                },
                "fields": "userEnteredFormat.numberFormat",
            }
        },
        {
            "repeatCell": {
                "range": range_value,
                "cell": {
                    "userEnteredFormat": {
                        "numberFormat": {"type": "NUMBER", "pattern": "#0.00"}
                    }
                },
                "fields": "userEnteredFormat.numberFormat",
            }
        },
    ]
    logger.info("Applying column number format(s)")
    batch_update_sheet(service, spreadsheet_id, requests)


def add_cond_format_rules(service, spreadsheet_id, sheet_id):
    """Add conditional formatting rules to ownership, points, and value fields."""
    color_yellow = {"red": 1.0, "green": 0.839, "blue": 0.4}
    color_white = {"red": 1.0, "green": 1.0, "blue": 1.0}
    color_red = {"red": 0.92, "green": 0.486, "blue": 0.451}
    color_green = {"red": 0.341, "green": 0.733, "blue": 0.541}
    range_ownership = {
        "sheetId": sheet_id,
        "startRowIndex": 1,
        "endRowIndex": 1001,
        "startColumnIndex": 5,  # F
        "endColumnIndex": 6,
    }
    range_points = {
        "sheetId": sheet_id,
        "startRowIndex": 1,
        "endRowIndex": 1001,
        "startColumnIndex": 6,  # G
        "endColumnIndex": 7,
    }
    value_range = {
        "sheetId": sheet_id,
        "startRowIndex": 1,
        "endRowIndex": 1001,
        "startColumnIndex": 7,  # H
        "endColumnIndex": 8,
    }
    # white --> yellow
    rule_white_yellow = {
        "minpoint": {"type": "MIN", "color": color_white},
        "maxpoint": {"type": "MAX", "color": color_yellow},
    }
    rule_red_white_green = {
        "minpoint": {
            # red
            "type": "MIN",
            "color": color_red,
        },
        "midpoint": {
            # white
            "type": "PERCENTILE",
            "value": "50",
            "color": color_white,
        },
        "maxpoint": {
            # green
            "type": "MAX",
            "color": color_green,
        },
    }
    # red --> white --> green
    requests = [
        {
            # ownership % rule for white --> yellow
            "addConditionalFormatRule": {
                "rule": {
                    "ranges": [range_ownership],
                    "gradientRule": rule_white_yellow,
                },
                "index": 0,
            }
        },
        {
            # points rule for red --> white --> green
            "addConditionalFormatRule": {
                "rule": {
                    "ranges": [range_points],
                    "gradientRule": rule_red_white_green,
                },
                "index": 0,
            }
        },
        {
            "addConditionalFormatRule": {
                "rule": {"ranges": [value_range], "gradientRule": rule_red_white_green},
                "index": 0,
            }
        },
    ]
    logger.info("Applying conditional formatting to sheet_id {}".format(sheet_id))
    batch_update_sheet(service, spreadsheet_id, requests)


def add_last_updated(service, spreadsheet_id, title):
    """Add (or update) the time in the header."""
    range = "{}!L1:Q1".format(title)
    now = datetime.datetime.now(tz=EST5EDT())
    values = [["Last Updated", "", now.strftime("%Y-%m-%d %H:%M:%S")]]
    body = {"values": values}
    value_input_option = "USER_ENTERED"
    result = (
        service.spreadsheets()
        .values()
        .update(
            spreadsheetId=spreadsheet_id,
            range=range,
            valueInputOption=value_input_option,
            body=body,
        )
        .execute()
    )
    logger.debug("{0} cells updated.".format(result.get("updatedCells")))


def update_sheet_title(service, spreadsheet_id, title):
    """Update spreadsheet title to reflect the correct sport."""
    requests = [
        {
            "updateSpreadsheetProperties": {
                "properties": {"title": title},
                "fields": "title",
            }
        }
    ]
    batch_update_sheet(service, spreadsheet_id, requests)


def batch_update_sheet(service, spreadsheet_id, requests):
    """Use function to run batchUpdate."""
    body = {"requests": requests}
    response = (
        service.spreadsheets()
        .batchUpdate(spreadsheetId=spreadsheet_id, body=body)
        .execute()
    )
    logger.debug("{0} cells updated.".format(len(response.get("replies"))))


def append_row(service, spreadsheet_id, range_name, values):
    """Append a set of values to a spreadsheet."""
    body = {"values": values}
    value_input_option = "USER_ENTERED"
    result = (
        service.spreadsheets()
        .values()
        .append(
            spreadsheetId=spreadsheet_id,
            range=range_name,
            valueInputOption=value_input_option,
            body=body,
        )
        .execute()
    )
    logger.info("{0} cells appended.".format(result.get("updates").get("updatedCells")))


def write_row(service, spreadsheet_id, range_name, values):
    """Write a set of values to a spreadsheet."""
    body = {"values": values}
    value_input_option = "USER_ENTERED"
    result = (
        service.spreadsheets()
        .values()
        .update(
            spreadsheetId=spreadsheet_id,
            range=range_name,
            valueInputOption=value_input_option,
            body=body,
        )
        .execute()
    )
    logger.debug("{0} cells updated.".format(result.get("updatedCells")))


def find_sheet_id(service, spreadsheet_id, title):
    sheet_metadata = service.spreadsheets().get(spreadsheetId=spreadsheet_id).execute()
    sheets = sheet_metadata.get("sheets", "")
    for sheet in sheets:
        if title in sheet["properties"]["title"]:
            logger.debug(
                "Sheet ID for {} is {}".format(title, sheet["properties"]["sheetId"])
            )
            return sheet["properties"]["sheetId"]
    # title = sheets[0].get("properties", {}).get("title", "Sheet1")
    # sheet_id = sheets[0].get("properties", {}).get("sheetId", 0)
    # print(title)
    # print(sheet_id)


def get_matchup_info(game_info, team_abbv):
    # wth is this?
    # logger.debug(game_info)
    if game_info in [
        "In Progress",
        "Final",
        "Postponed",
        "UNKNOWN",
        "Suspended",
        "Delayed",
    ]:
        return game_info

    # split game info into matchup_info
    home_team, a = game_info.split("@")
    away_team, match_time = a.split(" ", 1)
    # logger.debug("home_team: {} away_team: {} t: {}".format(
    #     home_team, away_team, match_time))
    # home_team, away_team = game_info.split(' ', 1)[0].split('@')
    if team_abbv == home_team:
        matchup_info = "vs. {}".format(away_team)
    else:
        matchup_info = "at {}".format(home_team)
    return matchup_info


def parse_lineup(sport, lineup, points, pmr, rank, player_dict):

    splt = lineup.split(" ")

    results = {"rank": rank, "pmr": pmr, "points": points}

    if sport == "NBA":
        positions = ["PG", "SG", "SF", "PF", "C", "G", "F", "UTIL"]
        # list comp for indicies of positions in splt
        indices = [i for i, pos in enumerate(splt) if pos in positions]
        # list comp for ending indices in splt. for splicing, the second argument is exclusive
        end_indices = [indices[i] for i in range(1, len(indices))]
        # append size of splt as last index
        end_indices.append(len(splt))
    elif "PGA" in sport:
        positions = ["G", "WG"]
        # list comp for indicies of positions in splt
        indices = [i for i, pos in enumerate(splt) if pos in positions]
        # list comp for ending indices in splt. for splicing, the second argument is exclusive
        end_indices = [indices[i] for i in range(1, len(indices))]
        # append size of splt as last index
        end_indices.append(len(splt))
    elif sport == "NFL":
        positions = ["QB", "RB", "WR", "TE", "FLEX", "DST"]
        # list comp for indicies of positions in splt
        indices = [i for i, pos in enumerate(splt) if pos in positions]
        # list comp for ending indices in splt. for splicing, the second argument is exclusive
        end_indices = [indices[i] for i in range(1, len(indices))]
        # append size of splt as last index
        end_indices.append(len(splt))
    elif sport == "CFB":
        positions = ["QB", "RB", "WR", "TE", "FLEX", "S-FLEX"]
        # list comp for indicies of positions in splt
        indices = [i for i, pos in enumerate(splt) if pos in positions]
        # list comp for ending indices in splt. for splicing, the second argument is exclusive
        end_indices = [indices[i] for i in range(1, len(indices))]
        # append size of splt as last index
        end_indices.append(len(splt))
    elif sport == "NHL":
        positions = ["C", "W", "D", "G", "UTIL"]
        # list comp for indicies of positions in splt
        indices = [i for i, pos in enumerate(splt) if pos in positions]
        # list comp for ending indices in splt. for splicing, the second argument is exclusive
        end_indices = [indices[i] for i in range(1, len(indices))]
        # append size of splt as last index
        end_indices.append(len(splt))
    elif sport == "MLB":
        positions = ["P", "C", "1B", "2B", "3B", "SS", "OF"]
        # list comp for indicies of positions in splt
        indices = [i for i, pos in enumerate(splt) if pos in positions]
        # list comp for ending indices in splt. for splicing, the second argument is exclusive
        end_indices = [indices[i] for i in range(1, len(indices))]
        # append size of splt as last index
        end_indices.append(len(splt))
    elif sport == "TEN":
        positions = ["P"]
        # list comp for indicies of positions in splt
        indices = [i for i, pos in enumerate(splt) if pos in positions]
        # list comp for ending indices in splt. for splicing, the second argument is exclusive
        end_indices = [indices[i] for i in range(1, len(indices))]
        # append size of splt as last index
        end_indices.append(len(splt))

    pts = 0
    value = 0

    for i, index in enumerate(indices):
        pos = splt[index]

        s = slice(index + 1, end_indices[i])
        name = splt[s]
        if name != "LOCKED":
            name = " ".join(name)

            # ensure name doesn't have any weird characters
            name = strip_accents(name)

            if name in player_dict:
                pts = player_dict[name]["pts"]
                value = player_dict[name]["value"]
                perc = player_dict[name]["perc"]
                salary = player_dict[name]["salary"]
                matchup_info = player_dict[name]["matchup_info"]
            else:
                pts = ""
                value = ""
                perc = ""
                salary = ""
                matchup_info = ""

        if "LOCKED" in name:
            name = "LOCKED 🔒"

        if sport == "NBA":
            results[pos] = {
                "name": name,
                "pts": pts,
                "value": value,
                "perc": perc,
                "salary": salary,
                "matchup_info": matchup_info,
            }
        elif sport == "TEN":
            if pos not in results:
                results[pos] = []

            results[pos].append(
                {
                    "name": name,
                    "pts": pts,
                    "value": value,
                    "perc": perc,
                    "salary": salary,
                    "matchup_info": matchup_info,
                }
            )
        elif "PGA" in sport:
            # because PGA has all 'G' , create a list rather than a dictionary
            if pos not in results:
                results[pos] = []

            # append each golfer to the results['G'] list
            results[pos].append(
                {
                    "name": name,
                    "pts": pts,
                    "value": value,
                    "perc": perc,
                    "salary": salary,
                }
            )
        elif sport == "NFL" or sport == "CFB":
            # create a list for RB and WR since there are multiple
            if pos == "RB" or pos == "WR":
                if pos not in results:
                    results[pos] = []
                # append to RB/WR list
                results[pos].append(
                    {
                        "name": name,
                        "pts": pts,
                        "value": value,
                        "perc": perc,
                        "salary": salary,
                    }
                )
            else:
                # set QB, TE, FLEX, DST, S-FLEX
                results[pos] = {
                    "name": name,
                    "pts": pts,
                    "value": value,
                    "perc": perc,
                    "salary": salary,
                }
        elif sport == "NHL":
            # create a list for C/W/D since there are multiple
            if pos == "C" or pos == "W" or pos == "D":
                if pos not in results:
                    results[pos] = []
                # append to RB/WR list
                results[pos].append(
                    {
                        "name": name,
                        "pts": pts,
                        "value": value,
                        "perc": perc,
                        "salary": salary,
                    }
                )
            else:
                # set G/UTIL
                results[pos] = {
                    "name": name,
                    "pts": pts,
                    "value": value,
                    "perc": perc,
                    "salary": salary,
                }
        elif sport == "MLB":
            # create a list for P/OF since there are multiple
            if pos == "P" or pos == "OF":
                if pos not in results:
                    results[pos] = []
                # append to P/OF list
                results[pos].append(
                    {
                        "name": name,
                        "pts": pts,
                        "value": value,
                        "perc": perc,
                        "salary": salary,
                        "matchup_info": matchup_info,
                    }
                )
            else:
                # set C/1B/2B/3B/SS
                results[pos] = {
                    "name": name,
                    "pts": pts,
                    "value": value,
                    "perc": perc,
                    "salary": salary,
                    "matchup_info": matchup_info,
                }

    return results


def write_NBA_lineup(lineup, bro):
    ordered_position = ["PG", "SG", "SF", "PF", "C", "G", "F", "UTIL"]
    values = [
        [bro, "", "PMR", lineup["pmr"], "rank", lineup["rank"]],
        ["Position", "Player", "Salary", "Pts", "Value", "Own"],
    ]
    rem_salary = 50000
    for position in ordered_position:
        values.append(
            [
                position,
                lineup[position]["name"],
                lineup[position]["salary"],
                lineup[position]["pts"],
                lineup[position]["value"],
                lineup[position]["perc"],
            ]
        )
        if lineup[position]["matchup_info"] in ["In Progress", "Final"]:
            rem_salary -= int(lineup[position]["salary"])

    values.append(["", "rem salary", rem_salary, lineup["points"], "", ""])
    return values


def write_PGA_lineup(lineup, bro):
    values = [
        [bro, "", "PMR", lineup["pmr"], "", ""],
        ["Position", "Player", "Salary", "Pts", "Value", "Own"],
    ]
    if "WG" in lineup:
        for golfer in lineup["WG"]:
            values.append(
                [
                    "WG",
                    golfer["name"],
                    golfer["salary"],
                    golfer["pts"],
                    golfer["value"],
                    golfer["perc"],
                ]
            )
    elif "G" in lineup:
        for golfer in lineup["G"]:
            values.append(
                [
                    "G",
                    golfer["name"],
                    golfer["salary"],
                    golfer["pts"],
                    golfer["value"],
                    golfer["perc"],
                ]
            )

    values.append(["rank", lineup["rank"], "", lineup["points"], "", ""])
    return values


def write_TEN_lineup(lineup, bro):
    values = [
        [bro, "", "PMR", lineup["pmr"], "", ""],
        ["Position", "Player", "Salary", "Pts", "Value", "Own"],
    ]
    if "P" in lineup:
        for p in lineup["P"]:
            values.append(
                ["P", p["name"], p["salary"], p["pts"], p["value"], p["perc"]]
            )

    values.append(["rank", lineup["rank"], "", lineup["points"], "", ""])
    return values


def write_NFL_lineup(lineup, bro):
    values = [
        [bro, "", "PMR", lineup["pmr"]],
        ["Position", "Player", "Points", "Value"],
    ]
    # append QB
    values.append(
        [
            "QB",
            lineup["QB"]["name"],
            lineup["QB"]["pts"],
            lineup["QB"]["value"],
            lineup["QB"]["perc"],
        ]
    )

    # append RBs
    for RB in lineup["RB"]:
        values.append(["RB", RB["name"], RB["pts"], RB["value"], RB["perc"]])

    # append WRs
    for WR in lineup["WR"]:
        values.append(["WR", WR["name"], WR["pts"], WR["value"], WR["perc"]])

    # append the other positions
    for pos in ["TE", "FLEX", "DST"]:
        values.append(
            [
                pos,
                lineup[pos]["name"],
                lineup[pos]["pts"],
                lineup[pos]["value"],
                lineup[pos]["perc"],
            ]
        )

    values.append(["rank", lineup["rank"], lineup["points"], ""])
    return values


def write_CFB_lineup(lineup, bro):
    values = [
        [bro, "", "PMR", lineup["pmr"]],
        ["Position", "Player", "Points", "Value"],
    ]
    # append QB
    values.append(
        ["QB", lineup["QB"]["name"], lineup["QB"]["pts"], lineup["QB"]["value"]]
    )
    # append RBs
    for RB in lineup["RB"]:
        values.append(["RB", RB["name"], RB["pts"], RB["value"]])
    # append WRs
    for WR in lineup["WR"]:
        values.append(["WR", WR["name"], WR["pts"], WR["value"]])

    for pos in ["FLEX", "S-FLEX"]:
        values.append(
            [pos, lineup[pos]["name"], lineup[pos]["pts"], lineup[pos]["value"]]
        )
    # append rank and points
    values.append(["rank", lineup["rank"], lineup["points"], ""])
    return values


def write_NHL_lineup(lineup, bro):
    values = [
        [bro, "", "PMR", lineup["pmr"]],
        ["Position", "Player", "Points", "Value"],
    ]
    # append C
    for C in lineup["C"]:
        values.append(["C", C["name"], C["pts"], C["value"]])
    # append W
    for W in lineup["W"]:
        values.append(["W", W["name"], W["pts"], W["value"]])
    # append D
    for D in lineup["D"]:
        values.append(["D", D["name"], D["pts"], D["value"]])
    # append G/UTIL
    for pos in ["G", "UTIL"]:
        values.append(
            [pos, lineup[pos]["name"], lineup[pos]["pts"], lineup[pos]["value"]]
        )
    # append rank and points
    values.append(["rank", lineup["rank"], lineup["points"], ""])
    return values


def write_MLB_lineup(lineup, bro):
    values = [
        [bro, "", "PMR", lineup["pmr"], "rank", lineup["rank"]],
        ["Position", "Player", "Salary", "Pts", "Value", "Own"],
    ]
    rem_salary = 50000
    # append P
    for P in lineup["P"]:
        values.append(["P", P["name"], P["salary"], P["pts"], P["value"], P["perc"]])
        if P["matchup_info"] in ["In Progress", "Final"]:
            rem_salary -= int(P["salary"])
    # append C/1B/2B/3B/SS
    for position in ["C", "1B", "2B", "3B", "SS"]:
        values.append(
            [
                position,
                lineup[position]["name"],
                lineup[position]["salary"],
                lineup[position]["pts"],
                lineup[position]["value"],
                lineup[position]["perc"],
            ]
        )
        if lineup[position]["matchup_info"] in ["In Progress", "Final"]:
            rem_salary -= int(lineup[position]["salary"])
    # append OF
    for OF in lineup["OF"]:
        values.append(
            ["OF", OF["name"], OF["salary"], OF["pts"], OF["value"], OF["perc"]]
        )
        if OF["matchup_info"] in ["In Progress", "Final"]:
            rem_salary -= int(OF["salary"])

    values.append(["", "rem salary", rem_salary, lineup["points"], "", ""])
    return values


def write_lineup(service, spreadsheet_id, sheet_id, lineup, sport):
    logger.debug("Sport == {} - trying to write_lineup()..".format(sport))
    # pre-defined google sheet lineup ranges
    # range 1 K3:N15  range 5: Q3:U15
    # range 2 K15:N25 range 6: Q15:U25
    # range 3 K27:N37 range 7: Q27:U37
    # range 4 K39:O49 range 8: Q39:U49
    # ranges = [
    #     "{}!K3:O15".format(sport),
    #     "{}!K15:O25".format(sport),
    #     "{}!K27:O37".format(sport),
    #     "{}!K39:O49".format(sport),
    #     "{}!Q3:U15".format(sport),
    #     "{}!Q15:U25".format(sport),
    #     "{}!Q27:U37".format(sport),
    #     "{}!Q39:U49".format(sport)
    # ]
    # NFL has an extra position, so it needs new ranges
    # NFL_ranges = [
    #     "{}!K3:O15".format(sport),
    #     "{}!K16:O27".format(sport),
    #     "{}!K29:O40".format(sport),
    #     "{}!K42:O53".format(sport),
    #     "{}!Q3:U15".format(sport),
    #     "{}!Q16:U27".format(sport),
    #     "{}!Q29:U40".format(sport),
    #     "{}!Q42:U53".format(sport)
    # ]

    ultimate_list = []
    lineup_mod = 4
    r = ""
    if sport == "NBA":
        for i, (k, v) in enumerate(sorted(lineup.items())):
            # print("i: {} K: {}\nv:{}".format(i, k, v))
            nba_mod = 11
            values = write_NBA_lineup(v, k)
            for j, z in enumerate(values):
                if i < lineup_mod:
                    ultimate_list.append(z)
                elif i >= lineup_mod:
                    mod = (i % lineup_mod) + ((i % lineup_mod) * nba_mod) + j
                    ultimate_list[mod].extend([""] + z)
            # append an empty list for spacing
            ultimate_list.append([])
        r = "{}!J3:V54".format(sport)
    elif "PGA" in sport:
        # for i, (k, v) in enumerate(sorted(lineup.items())):
        #     # print("i: {} K: {}\nv:{}".format(i, k, v))
        #     golf_mod = 9
        #     values = write_PGA_lineup(v, k)
        #     for j, z in enumerate(values):
        #         if i < lineup_mod:
        #             ultimate_list.append(z)
        #         elif i >= lineup_mod:
        #             # mod = (i % 4) + ((i % 4) * 10) + j
        #             mod = (i % lineup_mod) + ((i % lineup_mod) * golf_mod) + j
        #             ultimate_list[mod].extend([''] + z)
        #     # append an empty list for spacing
        #     ultimate_list.append([])
        ultimate_list = build_lineup_list(lineup, sport)
        r = "{}!L3:X54".format(sport)
    elif sport == "TEN":
        for i, (k, v) in enumerate(sorted(lineup.items())):
            # print("i: {} K: {}\nv:{}".format(i, k, v))
            ten_mod = 9
            values = write_TEN_lineup(v, k)
            for j, z in enumerate(values):
                if i < lineup_mod:
                    ultimate_list.append(z)
                elif i >= lineup_mod:
                    mod = (i % lineup_mod) + ((i % lineup_mod) * ten_mod) + j
                    ultimate_list[mod].extend([""] + z)
            # append an empty list for spacing
            ultimate_list.append([])
        r = "{}!J3:V54".format(sport)

    # elif sport == 'NFL':
    #     for i, (k, v) in enumerate(sorted(lineup.items())):
    #         # print("i: {} K: {}\nv:{}".format(i, k, v))
    #         values = write_NFL_lineup(v, k)
    #         logger.debug("trying to write line [{}] to {}".format(k, NFL_ranges[i]))
    #         # print(values)
    #         write_row(service, spreadsheet_id, NFL_ranges[i], values)
    # elif sport == 'CFB':
    #     for i, (k, v) in enumerate(sorted(lineup.items())):
    #         # print("i: {} K: {}\nv:{}".format(i, k, v))
    #         values = write_CFB_lineup(v, k)
    #         logger.debug("trying to write line [{}] to {}".format(k, ranges[i]))
    #         # print(values)
    #         write_row(service, spreadsheet_id, ranges[i], values)
    # elif sport == 'NHL':
    #     for i, (k, v) in enumerate(sorted(lineup.items())):
    #         # print("i: {} K: {}\nv:{}".format(i, k, v))
    #         values = write_NHL_lineup(v, k)
    #         logger.debug("trying to write line [{}] to {}".format(k, NFL_ranges[i]))
    #         # print(values)
    #         write_row(service, spreadsheet_id, NFL_ranges[i], values)
    elif sport == "MLB":
        for i, (k, v) in enumerate(sorted(lineup.items())):
            mlb_mod = 13
            values = write_MLB_lineup(v, k)
            for j, z in enumerate(values):
                if i < lineup_mod:
                    ultimate_list.append(z)
                elif i >= lineup_mod:
                    mod = (i % lineup_mod) + ((i % lineup_mod) * mlb_mod) + j
                    ultimate_list[mod].extend([""] + z)
            # append an empty list for spacing
            ultimate_list.append([])
        r = "{}!J3:V57".format(sport)

    logger.debug("trying to write all lineups to [{}]".format(r))
    write_row(service, spreadsheet_id, r, ultimate_list)


def build_lineup_list(lineup, sport):
    logger.debug("build_lineup_list(lineup, {})".format(sport))
    ultimate_list = []
    sport_mod = 1
    lineup_mod = 4

    if "PGA" in sport:
        sport_mod = 9
    elif "TEN" in sport:
        sport_mod = 9

    for i, (k, v) in enumerate(sorted(lineup.items())):
        # print("i: {} K: {}\nv:{}".format(i, k, v))
        values = write_PGA_lineup(v, k)
        for j, z in enumerate(values):
            if i < lineup_mod:
                ultimate_list.append(z)
            elif i >= lineup_mod:
                # mod = (i % 4) + ((i % 4) * 10) + j
                mod = (i % lineup_mod) + ((i % lineup_mod) * sport_mod) + j
                ultimate_list[mod].extend([""] + z)
        # append an empty list for spacing
        ultimate_list.append([])

    return ultimate_list


def read_salary_csv(fn):
    with open(fn, mode="r") as f:
        cr = csv.reader(f, delimiter=",")
        slate_list = list(cr)

        salary = {}
        for row in slate_list[1:]:
            if len(row) < 2:
                continue
            name = row[2]
            if name not in salary:
                salary[name] = {}
                salary[name]["salary"] = 0
                salary[name]["team_abbv"] = ""

            salary[name]["salary"] = row[5]
            salary[name]["game_info"] = row[6]
            salary[name]["team_abbv"] = row[7]
        return salary


def main():
    """Use contest ID to update Google Sheet with DFS results.

    Example export CSV/ZIP link
    https://www.draftkings.com/contest/exportfullstandingscsv/62753724

    Example salary CSV link
    https://www.draftkings.com/lineup/getavailableplayerscsv?contestTypeId=70&draftGroupId=22401
    12 = MLB 21 = NFL 9 = PGA 24 = NASCAR 10 = Soccer 13 = MMA
    """

    # text_cookie_issue()

    # parse arguments
    parser = argparse.ArgumentParser()
    choices = [
        "NBA",
        "NFL",
        "CFB",
        "PGAMain",
        "PGAWeekend",
        "PGAShowdown",
        "NHL",
        "MLB",
        "TEN",
    ]
    parser.add_argument(
        "-i", "--id", type=int, required=True, help="Contest ID from DraftKings"
    )
    parser.add_argument("-c", "--csv", help="Slate CSV from DraftKings")
    parser.add_argument(
        "-s",
        "--sport",
        choices=choices,
        required=True,
        help="Type of contest (NBA, NFL, PGA, CFB, NHL, or MLB)",
    )
    parser.add_argument("-v", "--verbose", help="Increase verbosity")
    args = parser.parse_args()

    now = datetime.datetime.now()
    logger.info("Current time: {}".format(now))

    dir = "/home/pi/Desktop/dk_salary_owner"
    # set the filename for the salary CSV
    if args.csv:
        fn = args.csv
    else:
        fn = "DKSalaries_{}_{}.csv".format(args.sport, now.strftime("%A"))

    contest_id = args.id
    sport = args.sport

    logger.debug(args)

    # read salary CSV
    salary_dict = read_salary_csv(fn)

    # pull contest standings
    fn2 = "contest-standings-{}.csv".format(contest_id)
    contest_list = pull_contest_zip(fn2, contest_id)
    parsed_lineup = {}
    bros = [
        "aplewandowski",
        "FlyntCoal",
        "Cubbiesftw23",
        "Mcoleman1902",
        "cglenn91",
        "Notorious",
        "Bra3105",
        "ChipotleAddict",
    ]
    values = []

    bro_lineups = {}
    player_dict = {}
    for i, row in enumerate(contest_list[1:]):
        rank = row[0]
        name = row[2]
        pmr = row[3]
        points = row[4]
        lineup = row[5]

        # find lineup for friends
        if name in bros:
            logger.info("found bro {}".format(name))
            bro_lineups[name] = {
                "rank": rank,
                "lineup": lineup,
                "pmr": pmr,
                "points": points,
            }

        stats = row[7:]
        if stats:
            # continue if empty (sometimes happens on the player columns in the standings)
            if all("" == s or s.isspace() for s in stats):
                continue

            name = strip_accents(stats[0])
            pos = stats[1]
            salary = int(salary_dict[name]["salary"])
            if "PGA" not in sport:
                team_abbv = salary_dict[name]["team_abbv"]
                game_info = salary_dict[name]["game_info"]
                matchup_info = get_matchup_info(game_info, team_abbv)
            else:
                team_abbv = ""
                matchup_info = ""

            perc = float(stats[2].replace("%", "")) / 100
            pts = float(stats[3])

            # calculate value
            if pts > 0:
                value = pts / (salary / 1000)
            else:
                value = 0

            player_dict[name] = {
                "pos": pos,
                "salary": salary,
                "perc": perc,
                "pts": pts,
                "value": value,
                "matchup_info": matchup_info,
            }
            # logger.debug("player_dict[{}]['matchup_info']: {}".format(
            #     name, player_dict[name]['matchup_info']))
            if "PGA" not in sport:
                values.append(
                    [pos, name, team_abbv, matchup_info, salary, perc, pts, value]
                )
            else:
                values.append([pos, name, salary, perc, pts])

    # logger.debug("player_dict:")
    # logger.debug(player_dict)
    # google sheets API boilerplate
    SCOPES = "https://www.googleapis.com/auth/spreadsheets"
    store = file.Storage(path.join(dir, "token.json"))
    creds = store.get()
    if not creds or creds.invalid:
        flow = client.flow_from_clientsecrets(path.join(dir, "token.json"), SCOPES)
        creds = tools.run_flow(flow, store)
    service = build("sheets", "v4", http=creds.authorize(Http()))

    for bro, v in bro_lineups.items():
        parsed_lineup[bro] = parse_lineup(
            sport, v["lineup"], v["points"], v["pmr"], v["rank"], player_dict
        )
        logger.debug("{} {}".format(bro, parsed_lineup[bro]))

    # call the Sheets API
    spreadsheet_id = "1Jv5nT-yUoEarkzY5wa7RW0_y0Dqoj8_zDrjeDs-pHL4"
    RANGE_NAME = "{}!A2:S".format(args.sport)
    sheet_id = find_sheet_id(service, spreadsheet_id, args.sport)

    logger.debug("Starting write_row")
    write_row(service, spreadsheet_id, RANGE_NAME, values)
    if parsed_lineup:
        logger.info("Writing lineup")
        write_lineup(service, spreadsheet_id, sheet_id, parsed_lineup, args.sport)
    # add_col_num_fmt(service, spreadsheet_id, sheet_id)
    # add_header_format(service, spreadsheet_id, sheet_id)
    # add_cond_format_rules(service, spreadsheet_id, sheet_id)
    add_last_updated(service, spreadsheet_id, args.sport)
    # update_sheet_title(service, spreadsheet_id, sheet_id, args.sport)


if __name__ == "__main__":
    logger.setLevel(logging.DEBUG)
    # formatter = logging.Formatter(fmt='%(asctime)s %(funcName)11s %(levelname)5s %(message)s',
    #                               datefmt='%Y-%m-%d %H:%M:%S')
    formatter = logging.Formatter(
        fmt="%(asctime)s %(funcName)20s %(levelname)5s %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S",
    )
    # configure and add stream handler
    ch = logging.StreamHandler()
    ch.setLevel(logging.DEBUG)
    ch.setFormatter(formatter)
    logger.addHandler(ch)
    main()
